{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6ef7f7-34d3-4c71-a11f-ebe652637337",
   "metadata": {},
   "source": [
    "# Get the FLOPs for various model architectures studied in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7d1de8-dd95-473b-ab0f-c45986d120a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30442934-dc97-4a43-97c2-630a5b601c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yiboyang/projects/code_releases/shallow-ntc\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089f2712-4f78-4202-b283-5bf20144dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beae7ef2-a617-4240-aa67-13507f2ce725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_compression as tfc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from absl import logging\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "import json\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f325c3-0837-40b9-ac56-9db65f530a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.profile_utils import get_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1c58a7-a7ac-4334-bb4b-a785062e1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd6e212-38fc-4490-8842-ebabd3c6b6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 19:38:59.977750: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "img_shape = [1, 512, 768, 3]\n",
    "x = tf.zeros(img_shape)\n",
    "npixels = np.prod(img_shape[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8022601-c8d6-42e0-b00f-7e0944539d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flops = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e2ccfc-2da3-4be5-9cb5-deee011ef33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = dict()\n",
    "def count_params(module):\n",
    "  return np.sum([np.prod(v.get_shape().as_list()) for v in module.trainable_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c6aac6-281c-47ad-bae0-7e4133f41a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trick to getting flops counter to work with custom keras model/module\n",
    "# (wrap the module in keras functional API):\n",
    "def get_model_with_known_input(module, input_shape):\n",
    "  input_layer = tf.keras.Input(shape=input_shape[1:])  # Input wants the shape of input tensor without batch dim\n",
    "  tmp_model = tf.keras.Model(inputs=input_layer, outputs=module(input_layer))\n",
    "  return tmp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151875c-eda6-4e76-ab49-2c891fe2daed",
   "metadata": {},
   "source": [
    "## Baseline - Factorized prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b611b7b5-f17a-44ce-873a-0c5451d2ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape (1, 32, 48, 320)\n",
      "xhat shape (1, 512, 768, 3)\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 512, 768, 3) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:From /extra/ucibdl0/yiboyang/envs/tf2.10/lib/python3.10/site-packages/tensorflow/python/ops/nn_ops.py:5250: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "{'f': 64198115328, 'g': 64198803456}\n",
      "{'f': 3394496, 'g': 3394179}\n"
     ]
    }
   ],
   "source": [
    "channels_base = 192\n",
    "bottleneck_size = 320\n",
    "\n",
    "ana = transforms.CNNAnalysis(channels_base=channels_base, output_channels=bottleneck_size)\n",
    "y = ana(x)\n",
    "print('y shape', y.shape)\n",
    "\n",
    "syn = transforms.CNNSynthesis(channels_base=channels_base, output_channels=3)\n",
    "xhat = syn(y)\n",
    "print('xhat shape', xhat.shape)\n",
    "\n",
    "# Set FLOPs\n",
    "method = 'Ballé 2017 Factorized Prior'\n",
    "all_flops[method] = {}\n",
    "all_params[method] = {}\n",
    "\n",
    "for (key, T) in zip(['f', 'g'], (ana, syn)):\n",
    "  flops = get_flops(T, batch_size=1).total_float_ops\n",
    "  all_flops[method][key] = flops\n",
    "  all_params[method][key] = count_params(T)\n",
    "print(all_flops[method])\n",
    "print(all_params[method])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3335d296-5694-402c-9a3b-b39368cf2cd6",
   "metadata": {},
   "source": [
    "## Baseline - Mean-Scale Hyperprior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45c074a-14fe-4fcb-b516-d1c188a356cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape (1, 32, 48, 320)\n",
      "z shape (1, 8, 12, 320)\n",
      "xhat shape (1, 512, 768, 3)\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 512, 768, 3) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 8, 12, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "channels_base = 192\n",
    "bottleneck_size = 320\n",
    "\n",
    "ana_act = 'gdn'\n",
    "ana = transforms.CNNAnalysis(channels_base=channels_base, output_channels=bottleneck_size, activation_type=ana_act)\n",
    "y = ana(x)\n",
    "print('y shape', y.shape)\n",
    "\n",
    "hana = transforms.HyperAnalysis(bottleneck_size)\n",
    "\n",
    "z = hana(y)\n",
    "print('z shape', z.shape)\n",
    "\n",
    "hsyn = transforms.HyperSynthesis(bottleneck_size)\n",
    "py_params = hsyn(z)\n",
    "syn_act = 'igdn'\n",
    "syn = transforms.CNNSynthesis(channels_base=channels_base, output_channels=3, activation_type=syn_act)\n",
    "xhat = syn(y)\n",
    "print('xhat shape', xhat.shape)\n",
    "\n",
    "# Set FLOPs\n",
    "method = 'Minnen 2018 Hyperprior'\n",
    "all_flops[method] = {}\n",
    "all_params[method] = {}\n",
    "\n",
    "for (key, T) in zip(['f', 'f_h', 'g', 'g_h'], (ana, hana, syn, hsyn)):\n",
    "  flops = get_flops(T, batch_size=1).total_float_ops\n",
    "  all_flops[method][key] = flops\n",
    "  all_params[method][key] = count_params(T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c54cdec1-ea02-4ef7-8dcb-69904c1d6a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ballé 2017 Factorized Prior': {'f': 3394496, 'g': 3394179},\n",
       " 'Minnen 2018 Hyperprior': {'f': 3431552,\n",
       "  'f_h': 6042560,\n",
       "  'g': 3431235,\n",
       "  'g_h': 9166240}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e56ab9-df95-4609-ba45-a0efeb4a6392",
   "metadata": {},
   "source": [
    "## Linearized CNNSynthesis, for comparison with JPEG-like syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91100ca2-2d81-4109-bcf5-700a143e626e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape (1, 32, 48, 320)\n",
      "z shape (1, 8, 12, 320)\n",
      "xhat shape (1, 512, 768, 3)\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "channels_base = 192\n",
    "bottleneck_size = 320\n",
    "\n",
    "ana_act = None\n",
    "ana = transforms.CNNAnalysis(channels_base=channels_base, output_channels=bottleneck_size, activation_type=ana_act)\n",
    "y = ana(x)\n",
    "print('y shape', y.shape)\n",
    "\n",
    "hana = transforms.HyperAnalysis(bottleneck_size)\n",
    "\n",
    "z = hana(y)\n",
    "print('z shape', z.shape)\n",
    "\n",
    "\n",
    "syn_act = None\n",
    "syn = transforms.CNNSynthesis(channels_base=channels_base, output_channels=3, activation_type=syn_act)\n",
    "xhat = syn(y)\n",
    "print('xhat shape', xhat.shape)\n",
    "\n",
    "flops = get_flops(syn, batch_size=1).total_float_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "828f8609-32db-4f8d-a7fe-a8445e048d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163266.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops / npixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35dcaa85-f2b4-4530-aab7-d03faf913d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81633.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops / npixels / 2   # in MACs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f48f44-33fe-454b-a0d3-ebcf5ea75ba6",
   "metadata": {},
   "source": [
    "## Proposed (1-layer) JPEG-like synthesis, with varying kernel sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02500cca-1c99-46fb-859e-06d86579aa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 , parameter count = 245763\n",
      "18 , parameter count = 311043\n",
      "20 , parameter count = 384003\n",
      "26 , parameter count = 648963\n",
      "32 , parameter count = 983043\n"
     ]
    }
   ],
   "source": [
    "jpeg_syn_flops = {}\n",
    "for k in [16, 18, 20, 26, 32]:\n",
    "  jpeg_syn = tf.keras.Sequential(tf.keras.layers.Conv2DTranspose(3, kernel_size=k, strides=16, padding='SAME', use_bias=True, input_shape=[32, 48, 320]))\n",
    "  flops = get_flops(jpeg_syn, batch_size=1).total_float_ops\n",
    "  print(k, ', parameter count =', count_params(jpeg_syn))\n",
    "  jpeg_syn_flops[k] = flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ab7323c-b470-4963-a8f7-713ca223ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params['JPEG-like syn. (proposed)'] = {'g': 311043}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bf9275d-950e-4946-ae15-286502893d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{16: 756154368, 18: 956694528, 20: 1180827648, 26: 1994784768, 32: 3021078528}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpeg_syn_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee9adee-ed35-40b5-966a-0043eabbbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pd.DataFrame(jpeg_syn_flops, index=['flops'])/ npixels).to_csv('results/jpeg_syn_fpp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c7c42-5904-454e-ba37-ec93f2bc9d5d",
   "metadata": {},
   "source": [
    "## Proposed 2-layer syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0977b04d-f2ae-4596-86e0-5e100d93fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape (1, 32, 48, 320)\n",
      "z shape (1, 8, 12, 320)\n",
      "xhat shape (1, 512, 768, 3)\n",
      "synthesis parameter count = 1299003\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 512, 768, 3) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 8, 12, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "channels_base = 192\n",
    "bottleneck_size = 320\n",
    "C1 = 12  # for the hidden layer size\n",
    "\n",
    "from common.elic import ElicAnalysis, ElicSynthesis\n",
    "\n",
    "ana = tf.keras.Sequential([\n",
    "  ElicAnalysis(channels=[192, 192, 192, 320])\n",
    "])\n",
    "y = ana(x)\n",
    "print('y shape', y.shape)\n",
    "\n",
    "hana = transforms.HyperAnalysis(bottleneck_size)\n",
    "\n",
    "z = hana(y)\n",
    "print('z shape', z.shape)\n",
    "\n",
    "hsyn = transforms.HyperSynthesis(bottleneck_size)\n",
    "py_params = hsyn(z)\n",
    "syn_act = 'igdn'\n",
    "syn = transforms.TwoLayerResSynthesis(channels=(C1, 3), strides=(8, 2),\n",
    "                                              kernel_sizes=(13, 5), activation_type=syn_act, res_type='conv')\n",
    "# flops counter crashes on a non-standard model like the above\n",
    "# with a residual connection. To get around this, we do the\n",
    "# following trick using keras functional API. \n",
    "syn_input = tf.keras.Input(shape=y.shape[1:])\n",
    "syn = tf.keras.Model(inputs=syn_input, outputs=syn(syn_input))\n",
    "xhat = syn(y)\n",
    "print('xhat shape', xhat.shape)\n",
    "\n",
    "print('synthesis parameter count =', count_params(syn))\n",
    "\n",
    "\n",
    "# Set FLOPs\n",
    "method = '2-layer syn. (proposed)'\n",
    "all_flops[method] = {}\n",
    "all_params[method] = {}\n",
    "\n",
    "for (key, T) in zip(['f', 'f_h', 'g', 'g_h'], (ana, hana, syn, hsyn)):\n",
    "  flops = get_flops(T, batch_size=1).total_float_ops\n",
    "  all_flops[method][key] = flops\n",
    "  all_params[method][key] = count_params(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92dfff79-aa71-477d-96c5-f29d2fd5b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params['2-layer syn. + SGA (proposed)'] = all_params['2-layer syn. (proposed)'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89809a88-1e87-4f1d-a6eb-9cac17350f0a",
   "metadata": {},
   "source": [
    "## Comparable 2-layer syn *without* residual connection, just two layers of conv transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f56f1544-281c-411e-beca-72cef8ed162a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4462610184, 11349.004577636719)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_base = 192\n",
    "bottleneck_size = 320\n",
    "C1 = 24  # for the hidden layer size of 2layerRes\n",
    "\n",
    "y = tf.random.normal([1, 32, 48, 320])\n",
    "syn_act = 'igdn'\n",
    "syn = transforms.TwoLayerSynthesis(channels=(C1, 3), strides=(8, 2),\n",
    "                                              kernel_sizes=(13, 5), activation_type=syn_act)\n",
    "\n",
    "# To trick flops counter to work using functional API\n",
    "syn_input = tf.keras.Input(shape=y.shape[1:])\n",
    "syn = tf.keras.Model(inputs=syn_input, outputs=syn(syn_input))\n",
    "\n",
    "flops = get_flops(syn, batch_size=1).total_float_ops\n",
    "flops, flops / npixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8033257-791f-4e41-ae6d-95e055df8d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300347"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77574ffa-3e3b-4700-ab7c-2fc274d2d797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10677.001190185547"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_flops['2-layer syn. (proposed)']['g'] / npixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "403c7f94-1dc1-48e3-80df-bef5e197de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equivalent no-residual syn uses 669 more FLOPs per pixel\n"
     ]
    }
   ],
   "source": [
    "print('Equivalent no-residual syn uses', 11349 - 10680, 'more FLOPs per pixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0232a1a0-ec5e-4503-a49f-f128cd175e2d",
   "metadata": {},
   "source": [
    "## For ELIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df1accf3-68a3-47ca-9b4f-9cb32993dc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape (1, 32, 48, 320)\n",
      "z shape (1, 8, 12, 320)\n",
      "xhat shape (1, 512, 768, 3)\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 512, 768, 3) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 8, 12, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "channels_base = 192\n",
    "bottleneck_size = 320\n",
    "from common.elic import ElicAnalysis, ElicSynthesis\n",
    "\n",
    "ana = tf.keras.Sequential([\n",
    "  ElicAnalysis(channels=[192, 192, 192, 320])\n",
    "])\n",
    "y = ana(x)\n",
    "print('y shape', y.shape)\n",
    "\n",
    "hana = transforms.HyperAnalysis(bottleneck_size)\n",
    "\n",
    "z = hana(y)\n",
    "print('z shape', z.shape)\n",
    "\n",
    "hsyn = transforms.HyperSynthesis(bottleneck_size)\n",
    "py_params = hsyn(z)\n",
    "syn = tf.keras.Sequential([\n",
    "  ElicSynthesis(channels=[192, 192, 192, 3])\n",
    "])\n",
    "xhat = syn(y)\n",
    "print('xhat shape', xhat.shape)\n",
    "\n",
    "# Set FLOPs\n",
    "method = 'He 2022 ELIC'\n",
    "all_flops[method] = {}\n",
    "all_params[method] = {}\n",
    "\n",
    "for (key, T) in zip(['f', 'f_h', 'g', 'g_h'], (ana, hana, syn, hsyn)):\n",
    "  flops = get_flops(T, batch_size=1).total_float_ops\n",
    "  all_flops[method][key] = flops\n",
    "  all_params[method][key] = count_params(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee7fdabe-24c3-4908-8d5f-0a88b1502469",
   "metadata": {},
   "outputs": [],
   "source": [
    "### back-of-envelope calculation for the CHARM component of the ELIC hyperprior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d96c614-380e-460f-96b6-3e7bcb4ce2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from ms2020 to allow custom slice_depth\n",
    "import functools\n",
    "class SliceTransform(tf.keras.layers.Layer):\n",
    "    \"\"\"Transform for channel-conditional params and latent residual prediction.\"\"\"\n",
    "\n",
    "    def __init__(self, slice_depth=None, latent_depth=None, num_slices=None):\n",
    "        super().__init__()\n",
    "        conv = functools.partial(\n",
    "            tfc.SignalConv2D, corr=False, strides_up=1, padding=\"same_zeros\",\n",
    "            use_bias=True, kernel_parameter=\"variable\")\n",
    "\n",
    "        # Note that the number of channels in the output tensor must match the\n",
    "        # size of the corresponding slice. If we have 10 slices and a bottleneck\n",
    "        # with 320 channels, the output is 320 / 10 = 32 channels.\n",
    "        if slice_depth is None:\n",
    "          slice_depth = latent_depth // num_slices\n",
    "          if slice_depth * num_slices != latent_depth:\n",
    "              raise ValueError(\"Slices do not evenly divide latent depth (%d / %d)\" % (\n",
    "                  latent_depth, num_slices))\n",
    "\n",
    "        self.transform = tf.keras.Sequential([\n",
    "            conv(224, (5, 5), name=\"layer_0\", activation=tf.nn.relu),\n",
    "            conv(128, (5, 5), name=\"layer_1\", activation=tf.nn.relu),\n",
    "            conv(slice_depth, (3, 3), name=\"layer_2\", activation=None),\n",
    "        ])\n",
    "\n",
    "    def call(self, tensor):\n",
    "        return self.transform(tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33c59e51-6d22-4053-8bf1-9ebba2059b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_means, latent_scales = tf.split(py_params, 2, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c8c3df7-2435-4957-ba4a-a6054c047019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 48, 320])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa6a3acc-f40d-4edd-9301-27de6eb740ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_slices = 5\n",
    "max_support_slices = 5\n",
    "\n",
    "latent_depth = 320\n",
    "\n",
    "# y_slices = tf.split(y, num_slices, axis=-1)   # CHARM\n",
    "# cc_mean_transforms = [SliceTransform(latent_depth=latent_depth, num_slices=num_slices) for _ in range(num_slices)]\n",
    "\n",
    "elic_slice_depths = [16, 16, 32, 64, latent_depth-128]\n",
    "y_slices = tf.split(y, elic_slice_depths, axis=-1)  # ELIC\n",
    "cc_mean_transforms = [SliceTransform(slice_depth=sd) for sd in elic_slice_depths]\n",
    "cc_mean_transforms_Models = []  # tmp keras Models for computing flops\n",
    "\n",
    "\n",
    "y_hat_slices = []\n",
    "\n",
    "for slice_index, y_slice in enumerate(y_slices):\n",
    "    # Model may condition on only a subset of previous slices.\n",
    "    support_slices = (y_hat_slices if max_support_slices < 0 else\n",
    "                      y_hat_slices[:max_support_slices])\n",
    "\n",
    "    # Predict mu and sigma for the current slice.\n",
    "    mean_support = tf.concat([latent_means] + support_slices, axis=-1)\n",
    "    mu = cc_mean_transforms[slice_index](mean_support)\n",
    "    cc_mean_transforms_Models.append(get_model_with_known_input(cc_mean_transforms[slice_index], mean_support.shape))\n",
    "    # mu = mu[:, :y_shape[0], :y_shape[1], :]\n",
    "\n",
    "    # # Note that in this implementation, `sigma` represents scale indices,\n",
    "    # # not actual scale values.\n",
    "    # scale_support = tf.concat([latent_scales] + support_slices, axis=-1)\n",
    "    # sigma = self.cc_scale_transforms[slice_index](scale_support)\n",
    "    y_hat_slice = mu\n",
    "    \n",
    "    y_hat_slices.append(y_hat_slice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25913eda-3003-4f88-aa56-2e872e231f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 320) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 336) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 352) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 384) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'args_0:0' shape=(1, 32, 48, 448) dtype=float32>]. Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "elic_flops_across_slices = [get_flops(T.transform, batch_size=1).total_float_ops for T in cc_mean_transforms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72724362-ad62-40ce-afe1-6d520db5b30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19745.4375, 20445.4375, 21289.5   , 22977.625 , 26930.125 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(elic_flops_across_slices) / npixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2dbb8cd-1d41-4a9a-8a98-fb255e89796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "elic_flops_across_slices = [get_flops(T, batch_size=1).total_float_ops for T in cc_mean_transforms_Models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20fe47fc-1bf8-4957-ab20-c941adc45fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19745.4375, 20445.4375, 21289.5   , 22977.625 , 26930.125 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(elic_flops_across_slices) / npixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb2ddc-df9d-4175-b990-c2a518c3acd4",
   "metadata": {},
   "source": [
    "### Manually add to hyper synthesis FLOPs; not worrying about the checkerboard stuff for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20b1f54c-a080-4768-9e35-7d2b57a98628",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flops['He 2022 ELIC']['g_h'] = all_flops['Minnen 2018 Hyperprior']['g_h'] + np.sum(elic_flops_across_slices) * 2 # x2 for both mean and scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ab89f-1e77-407c-8489-e858ed01eb44",
   "metadata": {},
   "source": [
    "### Add a few more methods with derived stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31463247-1dee-40b1-ae44-e93712e59ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'JPEG-like syn. (proposed)'\n",
    "all_flops[method] = all_flops['Minnen 2018 Hyperprior'].copy()  # COPY!\n",
    "all_flops[method]['f'] = all_flops['He 2022 ELIC']['f']\n",
    "all_flops[method]['g'] = jpeg_syn_flops[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46a5202f-70f3-4d93-a4d8-39da20782fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = '2-layer syn. + SGA (proposed)'\n",
    "all_flops[method] = all_flops['2-layer syn. (proposed)'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9056b8-d158-4ada-a212-e48f86948d41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add EVC based on paper Fig. 2 of the paper https://openreview.net/pdf?id=XUxad2Gj40n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fa7bfef-0ea4-4dd7-80cc-b579f9185cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'Wang 2023 EVC' # corresponding to the \"Large\" configuration\n",
    "all_flops[method] = dict(\n",
    "  f=549.92 * 1e9 * 2, g=538.83 * 1e9 * 2, f_h=3.89 * 1e9 * 2, g_h=(44.68+28.06) * 1e9 * 2)\n",
    "all_flops[method] = {k: (v / 1920 / 1088) * npixels for (k,v) in all_flops[method].items()}\n",
    "\n",
    "all_params[method] = {'f': 3.19e6, 'g': 3.38e6}  # From Table 3 in the Appendix\n",
    "\n",
    "# Note the paper listed MACs for 1920 x 1088 imgs; hence my conversion above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0496a4d5-0850-43c1-9547-d5b14e54ee0a",
   "metadata": {},
   "source": [
    "## Save results for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25375924-7049-4507-9fa2-c8c82cb53b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39e180b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpp = pd.DataFrame(all_flops) / npixels\n",
    "all_fpp = all_fpp.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca7420d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>f_h</th>\n",
       "      <th>g_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ballé 2017 Factorized Prior</th>\n",
       "      <td>163264.250000</td>\n",
       "      <td>163266.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnen 2018 Hyperprior</th>\n",
       "      <td>187583.098145</td>\n",
       "      <td>187584.848145</td>\n",
       "      <td>13451.640625</td>\n",
       "      <td>30354.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-layer syn. (proposed)</th>\n",
       "      <td>510563.750000</td>\n",
       "      <td>10677.001190</td>\n",
       "      <td>13451.640625</td>\n",
       "      <td>30354.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He 2022 ELIC</th>\n",
       "      <td>510563.750000</td>\n",
       "      <td>510565.500000</td>\n",
       "      <td>13451.640625</td>\n",
       "      <td>253130.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPEG-like syn. (proposed)</th>\n",
       "      <td>510563.750000</td>\n",
       "      <td>2433.000000</td>\n",
       "      <td>13451.640625</td>\n",
       "      <td>30354.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-layer syn. + SGA (proposed)</th>\n",
       "      <td>510563.750000</td>\n",
       "      <td>10677.001190</td>\n",
       "      <td>13451.640625</td>\n",
       "      <td>30354.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wang 2023 EVC</th>\n",
       "      <td>526501.225490</td>\n",
       "      <td>515883.501838</td>\n",
       "      <td>3724.341299</td>\n",
       "      <td>69642.310049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           f              g           f_h  \\\n",
       "Ballé 2017 Factorized Prior    163264.250000  163266.000000           NaN   \n",
       "Minnen 2018 Hyperprior         187583.098145  187584.848145  13451.640625   \n",
       "2-layer syn. (proposed)        510563.750000   10677.001190  13451.640625   \n",
       "He 2022 ELIC                   510563.750000  510565.500000  13451.640625   \n",
       "JPEG-like syn. (proposed)      510563.750000    2433.000000  13451.640625   \n",
       "2-layer syn. + SGA (proposed)  510563.750000   10677.001190  13451.640625   \n",
       "Wang 2023 EVC                  526501.225490  515883.501838   3724.341299   \n",
       "\n",
       "                                         g_h  \n",
       "Ballé 2017 Factorized Prior              NaN  \n",
       "Minnen 2018 Hyperprior          30354.687500  \n",
       "2-layer syn. (proposed)         30354.687500  \n",
       "He 2022 ELIC                   253130.937500  \n",
       "JPEG-like syn. (proposed)       30354.687500  \n",
       "2-layer syn. + SGA (proposed)   30354.687500  \n",
       "Wang 2023 EVC                   69642.310049  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1276f7d4-00fe-42c7-a8cb-1e63cd70a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpp['f_tot'] = all_fpp['f'] + all_fpp['f_h']\n",
    "all_fpp['g_tot'] = all_fpp['g'] + all_fpp['g_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5008cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpp.to_csv('results/all_fpp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e879873",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpp = pd.read_csv('results/all_fpp.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ea7a852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>f_h</th>\n",
       "      <th>g_h</th>\n",
       "      <th>f_tot</th>\n",
       "      <th>g_tot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ballé 2017 Factorized Prior</th>\n",
       "      <td>163264.250000</td>\n",
       "      <td>163266.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnen 2018 Hyperprior</th>\n",
       "      <td>187583.098145</td>\n",
       "      <td>187584.848145</td>\n",
       "      <td>13451.640625</td>\n",
       "      <td>30354.687500</td>\n",
       "      <td>201034.738770</td>\n",
       "      <td>217939.535645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-layer syn. (proposed)</th>\n",
       "      <td>510563.750000</td>\n",
       "      <td>10677.001190</td>\n",
       "      <td>13451.640625</td>\n",
       "      <td>30354.687500</td>\n",
       "      <td>524015.390625</td>\n",
       "      <td>41031.688690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He 2022 ELIC</th>\n",
       "      <td>510563.750000</td>\n",
       "      <td>510565.500000</td>\n",
       "      <td>13451.640625</td>\n",
       "      <td>253130.937500</td>\n",
       "      <td>524015.390625</td>\n",
       "      <td>763696.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPEG-like syn. (proposed)</th>\n",
       "      <td>510563.750000</td>\n",
       "      <td>2433.000000</td>\n",
       "      <td>13451.640625</td>\n",
       "      <td>30354.687500</td>\n",
       "      <td>524015.390625</td>\n",
       "      <td>32787.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-layer syn. + SGA (proposed)</th>\n",
       "      <td>510563.750000</td>\n",
       "      <td>10677.001190</td>\n",
       "      <td>13451.640625</td>\n",
       "      <td>30354.687500</td>\n",
       "      <td>524015.390625</td>\n",
       "      <td>41031.688690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wang 2023 EVC</th>\n",
       "      <td>526501.225490</td>\n",
       "      <td>515883.501838</td>\n",
       "      <td>3724.341299</td>\n",
       "      <td>69642.310049</td>\n",
       "      <td>530225.566789</td>\n",
       "      <td>585525.811887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           f              g           f_h  \\\n",
       "Ballé 2017 Factorized Prior    163264.250000  163266.000000           NaN   \n",
       "Minnen 2018 Hyperprior         187583.098145  187584.848145  13451.640625   \n",
       "2-layer syn. (proposed)        510563.750000   10677.001190  13451.640625   \n",
       "He 2022 ELIC                   510563.750000  510565.500000  13451.640625   \n",
       "JPEG-like syn. (proposed)      510563.750000    2433.000000  13451.640625   \n",
       "2-layer syn. + SGA (proposed)  510563.750000   10677.001190  13451.640625   \n",
       "Wang 2023 EVC                  526501.225490  515883.501838   3724.341299   \n",
       "\n",
       "                                         g_h          f_tot          g_tot  \n",
       "Ballé 2017 Factorized Prior              NaN            NaN            NaN  \n",
       "Minnen 2018 Hyperprior          30354.687500  201034.738770  217939.535645  \n",
       "2-layer syn. (proposed)         30354.687500  524015.390625   41031.688690  \n",
       "He 2022 ELIC                   253130.937500  524015.390625  763696.437500  \n",
       "JPEG-like syn. (proposed)       30354.687500  524015.390625   32787.687500  \n",
       "2-layer syn. + SGA (proposed)   30354.687500  524015.390625   41031.688690  \n",
       "Wang 2023 EVC                   69642.310049  530225.566789  585525.811887  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ffcf9-2616-48f6-8c40-e1a2feab29c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1ffe2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>f_h</th>\n",
       "      <th>g_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ballé 2017 Factorized Prior</th>\n",
       "      <td>3394496.0</td>\n",
       "      <td>3394179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnen 2018 Hyperprior</th>\n",
       "      <td>3431552.0</td>\n",
       "      <td>3431235.0</td>\n",
       "      <td>6042560.0</td>\n",
       "      <td>9166240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPEG-like syn. (proposed)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>311043.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-layer syn. (proposed)</th>\n",
       "      <td>7337792.0</td>\n",
       "      <td>1299003.0</td>\n",
       "      <td>6042560.0</td>\n",
       "      <td>9166240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-layer syn. + SGA (proposed)</th>\n",
       "      <td>7337792.0</td>\n",
       "      <td>1299003.0</td>\n",
       "      <td>6042560.0</td>\n",
       "      <td>9166240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He 2022 ELIC</th>\n",
       "      <td>7337792.0</td>\n",
       "      <td>7337475.0</td>\n",
       "      <td>6042560.0</td>\n",
       "      <td>9166240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wang 2023 EVC</th>\n",
       "      <td>3190000.0</td>\n",
       "      <td>3380000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       f          g        f_h        g_h\n",
       "Ballé 2017 Factorized Prior    3394496.0  3394179.0        NaN        NaN\n",
       "Minnen 2018 Hyperprior         3431552.0  3431235.0  6042560.0  9166240.0\n",
       "JPEG-like syn. (proposed)            NaN   311043.0        NaN        NaN\n",
       "2-layer syn. (proposed)        7337792.0  1299003.0  6042560.0  9166240.0\n",
       "2-layer syn. + SGA (proposed)  7337792.0  1299003.0  6042560.0  9166240.0\n",
       "He 2022 ELIC                   7337792.0  7337475.0  6042560.0  9166240.0\n",
       "Wang 2023 EVC                  3190000.0  3380000.0        NaN        NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params_df = pd.DataFrame(all_params)\n",
    "all_params_df = all_params_df.transpose()\n",
    "all_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b01b4aff-4612-47dd-81a9-ff009069f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params_df.to_csv('results/all_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21485d4a-d494-4945-8bea-659d44df1048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
